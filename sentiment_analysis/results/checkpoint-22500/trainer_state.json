{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 22500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.022222222222222223,
      "grad_norm": 1.930603265762329,
      "learning_rate": 4.962962962962963e-05,
      "loss": 0.446,
      "step": 500
    },
    {
      "epoch": 0.044444444444444446,
      "grad_norm": 2.179600954055786,
      "learning_rate": 4.926e-05,
      "loss": 0.396,
      "step": 1000
    },
    {
      "epoch": 0.06666666666666667,
      "grad_norm": 1.8203277587890625,
      "learning_rate": 4.888962962962963e-05,
      "loss": 0.3806,
      "step": 1500
    },
    {
      "epoch": 0.08888888888888889,
      "grad_norm": 3.24397349357605,
      "learning_rate": 4.8519259259259264e-05,
      "loss": 0.3736,
      "step": 2000
    },
    {
      "epoch": 0.1111111111111111,
      "grad_norm": 2.1564972400665283,
      "learning_rate": 4.8148888888888894e-05,
      "loss": 0.3611,
      "step": 2500
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 2.855088949203491,
      "learning_rate": 4.777851851851852e-05,
      "loss": 0.3665,
      "step": 3000
    },
    {
      "epoch": 0.15555555555555556,
      "grad_norm": 2.424861431121826,
      "learning_rate": 4.740814814814815e-05,
      "loss": 0.3565,
      "step": 3500
    },
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 1.9762729406356812,
      "learning_rate": 4.703777777777778e-05,
      "loss": 0.3485,
      "step": 4000
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.068711519241333,
      "learning_rate": 4.666740740740741e-05,
      "loss": 0.3554,
      "step": 4500
    },
    {
      "epoch": 0.2222222222222222,
      "grad_norm": 2.3643128871917725,
      "learning_rate": 4.629703703703704e-05,
      "loss": 0.3471,
      "step": 5000
    },
    {
      "epoch": 0.24444444444444444,
      "grad_norm": 2.058966875076294,
      "learning_rate": 4.592666666666667e-05,
      "loss": 0.3556,
      "step": 5500
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 2.080549716949463,
      "learning_rate": 4.55562962962963e-05,
      "loss": 0.3477,
      "step": 6000
    },
    {
      "epoch": 0.28888888888888886,
      "grad_norm": 2.494450807571411,
      "learning_rate": 4.518592592592593e-05,
      "loss": 0.3468,
      "step": 6500
    },
    {
      "epoch": 0.3111111111111111,
      "grad_norm": 1.7143117189407349,
      "learning_rate": 4.48162962962963e-05,
      "loss": 0.3432,
      "step": 7000
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 1.6511276960372925,
      "learning_rate": 4.444592592592593e-05,
      "loss": 0.3436,
      "step": 7500
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 2.795764923095703,
      "learning_rate": 4.407555555555556e-05,
      "loss": 0.3422,
      "step": 8000
    },
    {
      "epoch": 0.37777777777777777,
      "grad_norm": 2.2625536918640137,
      "learning_rate": 4.370518518518519e-05,
      "loss": 0.3381,
      "step": 8500
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.2798337936401367,
      "learning_rate": 4.333555555555556e-05,
      "loss": 0.338,
      "step": 9000
    },
    {
      "epoch": 0.4222222222222222,
      "grad_norm": 2.1599528789520264,
      "learning_rate": 4.2965185185185186e-05,
      "loss": 0.339,
      "step": 9500
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 2.1222612857818604,
      "learning_rate": 4.2594814814814815e-05,
      "loss": 0.3334,
      "step": 10000
    },
    {
      "epoch": 0.4666666666666667,
      "grad_norm": 2.31209397315979,
      "learning_rate": 4.2224444444444444e-05,
      "loss": 0.3376,
      "step": 10500
    },
    {
      "epoch": 0.4888888888888889,
      "grad_norm": 2.2698028087615967,
      "learning_rate": 4.185407407407407e-05,
      "loss": 0.3332,
      "step": 11000
    },
    {
      "epoch": 0.5111111111111111,
      "grad_norm": 2.1065685749053955,
      "learning_rate": 4.148370370370371e-05,
      "loss": 0.3356,
      "step": 11500
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 1.5841742753982544,
      "learning_rate": 4.111407407407408e-05,
      "loss": 0.334,
      "step": 12000
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 1.992223858833313,
      "learning_rate": 4.0743703703703706e-05,
      "loss": 0.3288,
      "step": 12500
    },
    {
      "epoch": 0.5777777777777777,
      "grad_norm": 2.3859200477600098,
      "learning_rate": 4.0373333333333335e-05,
      "loss": 0.3294,
      "step": 13000
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.5666102170944214,
      "learning_rate": 4.0002962962962964e-05,
      "loss": 0.3337,
      "step": 13500
    },
    {
      "epoch": 0.6222222222222222,
      "grad_norm": 2.1660563945770264,
      "learning_rate": 3.963333333333333e-05,
      "loss": 0.3343,
      "step": 14000
    },
    {
      "epoch": 0.6444444444444445,
      "grad_norm": 1.7232130765914917,
      "learning_rate": 3.926296296296296e-05,
      "loss": 0.3272,
      "step": 14500
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 2.460545778274536,
      "learning_rate": 3.88925925925926e-05,
      "loss": 0.3239,
      "step": 15000
    },
    {
      "epoch": 0.6888888888888889,
      "grad_norm": 1.5024666786193848,
      "learning_rate": 3.8522222222222226e-05,
      "loss": 0.3313,
      "step": 15500
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 1.6651052236557007,
      "learning_rate": 3.8152592592592594e-05,
      "loss": 0.3244,
      "step": 16000
    },
    {
      "epoch": 0.7333333333333333,
      "grad_norm": 2.2649953365325928,
      "learning_rate": 3.778222222222222e-05,
      "loss": 0.3238,
      "step": 16500
    },
    {
      "epoch": 0.7555555555555555,
      "grad_norm": 1.7864890098571777,
      "learning_rate": 3.741185185185185e-05,
      "loss": 0.3256,
      "step": 17000
    },
    {
      "epoch": 0.7777777777777778,
      "grad_norm": 1.8196848630905151,
      "learning_rate": 3.704148148148148e-05,
      "loss": 0.3211,
      "step": 17500
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.3337013721466064,
      "learning_rate": 3.667185185185185e-05,
      "loss": 0.3223,
      "step": 18000
    },
    {
      "epoch": 0.8222222222222222,
      "grad_norm": 1.7917277812957764,
      "learning_rate": 3.630148148148148e-05,
      "loss": 0.3208,
      "step": 18500
    },
    {
      "epoch": 0.8444444444444444,
      "grad_norm": 2.035700559616089,
      "learning_rate": 3.5931111111111115e-05,
      "loss": 0.3245,
      "step": 19000
    },
    {
      "epoch": 0.8666666666666667,
      "grad_norm": 1.5823310613632202,
      "learning_rate": 3.5560740740740744e-05,
      "loss": 0.3261,
      "step": 19500
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 1.6751880645751953,
      "learning_rate": 3.519037037037037e-05,
      "loss": 0.3225,
      "step": 20000
    },
    {
      "epoch": 0.9111111111111111,
      "grad_norm": 2.4611268043518066,
      "learning_rate": 3.482074074074074e-05,
      "loss": 0.3237,
      "step": 20500
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 1.3783899545669556,
      "learning_rate": 3.445037037037037e-05,
      "loss": 0.3201,
      "step": 21000
    },
    {
      "epoch": 0.9555555555555556,
      "grad_norm": 1.6533749103546143,
      "learning_rate": 3.408e-05,
      "loss": 0.3206,
      "step": 21500
    },
    {
      "epoch": 0.9777777777777777,
      "grad_norm": 1.2716742753982544,
      "learning_rate": 3.370962962962963e-05,
      "loss": 0.3205,
      "step": 22000
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.6796464920043945,
      "learning_rate": 3.333925925925926e-05,
      "loss": 0.3167,
      "step": 22500
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.31390780210494995,
      "eval_runtime": 387.476,
      "eval_samples_per_second": 412.929,
      "eval_steps_per_second": 12.904,
      "step": 22500
    }
  ],
  "logging_steps": 500,
  "max_steps": 67500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.9075645587456e+17,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
